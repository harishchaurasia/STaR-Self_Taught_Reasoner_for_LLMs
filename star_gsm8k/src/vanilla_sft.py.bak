#!/usr/bin/env python3
"""
Full single-file SFT launcher using training loop style.
- Prepares GSM8K SFT JSONL if missing.
- Builds DataLoaders and calls train(...) directly.
- Saves epoch checkpoints to out_dir/epoch{n}.

Usage (quick small run, ~500 examples):
  python3 run/train_vanilla_fullscript.py --subset 500 --epochs 1 --batch 1 --grad_accum 8 --out checkpoints/vanilla_sft_direct_500

For full run (be careful, big & slow):
  python3 run/train_vanilla_fullscript.py --subset 0 --epochs 2 --batch 1 --grad_accum 8 --out checkpoints/vanilla_sft_direct_full

"""

import argparse
import json
import os
import math
import random
import time
from datetime import datetime
from pathlib import Path
from contextlib import contextmanager, nullcontext

import torch
from torch import optim
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import datasets
from transformers import AutoTokenizer, AutoModelForCausalLM
from torch.cuda.amp import autocast, GradScaler

# ---------------------
# Minimal stubs / helpers (to avoid external dependencies)
# ---------------------
class MemoryTrace:
    """Stub to mimic memory tracing context manager used by the original train()."""
    def __enter__(self):
        return self
    def __exit__(self, exc_type, exc, tb):
        pass
    def print_stats(self):
        pass

@contextmanager
def profile(train_config, local_rank=None):
    """Stub profile context manager used in original code."""
    class P:
        def step(self): pass
        def is_done(self): return False
        def get_flops_per_sec(self): return 0.0
    yield P()

def save_to_json(filename, train_step_loss, train_loss, train_step_perplexity, train_prep,
                 val_step_loss, val_loss, val_step_perplexity, val_prep):
    """Save metrics in a compact JSON for plotting later (append/overwrite)."""
    try:
        out = {
            "train_step_loss": train_step_loss,
            "train_loss": train_loss,
            "train_step_perplexity": train_step_perplexity,
            "train_prep": train_prep,
            "val_step_loss": val_step_loss,
            "val_loss": val_loss,
            "val_step_perplexity": val_step_perplexity,
            "val_prep": val_prep,
            "ts": datetime.now().isoformat(),
        }
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(out, f, indent=2)
    except Exception as e:
        print("Warning: save_to_json failed:", e)

# ---------------------
# Data prep: create SFT JSONL from GSM8K train
# ---------------------
def prepare_gsm8k_sft(out_path="data/gsm8k_train_sft.jsonl"):
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    if os.path.exists(out_path) and os.path.getsize(out_path) > 0:
        print(f"[prepare] {out_path} already exists; skipping creation.")
        return out_path
    print("[prepare] Downloading GSM8K train and creating SFT JSONL...")
    ds = datasets.load_dataset("gsm8k", "main")["train"]
    with open(out_path, "w", encoding="utf-8") as f:
        for i, ex in enumerate(ds):
            q = ex.get("question","").strip()
            # choose the best available rationale/solution field if present
            rationale = ex.get("solution") or ex.get("explanation") or ex.get("answer", "")
            ans = ex.get("answer", "").strip()
            j = {"id": i, "question": q, "rationale": rationale, "answer": ans}
            f.write(json.dumps(j, ensure_ascii=False) + "\n")
    print(f"[prepare] Wrote {len(ds)} examples to {out_path}")
    return out_path

# ---------------------
# Tokenize & mask labels for causal LM
# ---------------------
def tokenize_and_mask(tokenizer, question, rationale, answer, prompt_template="Q: {q}\nA: "):
    # Build prompt and target strings
    prompt_text = prompt_template.format(q=question)
    target_text = (rationale.strip() + "\nFinal answer: " + answer.strip()) if rationale and rationale.strip() else ("Final answer: " + answer.strip())

    # encode without adding special tokens automatically (we control layout)
    prompt_ids = tokenizer(prompt_text, add_special_tokens=False)["input_ids"]
    target_ids = tokenizer(target_text, add_special_tokens=False)["input_ids"]

    input_ids = prompt_ids + target_ids
    attention_mask = [1] * len(input_ids)
    labels = [-100] * len(prompt_ids) + target_ids
    return input_ids, attention_mask, labels

# ---------------------
# PyTorch Dataset and collator
# ---------------------
class JsonlCausalDataset(Dataset):
    def __init__(self, path, tokenizer, max_examples=None, prompt_template="Q: {q}\nA: "):
        self.rows = []
        with open(path, "r", encoding="utf-8") as f:
            for ln in f:
                if not ln.strip(): continue
                self.rows.append(json.loads(ln))
        if max_examples and max_examples > 0:
            self.rows = self.rows[:max_examples]
        self.tokenizer = tokenizer
        self.prompt_template = prompt_template

    def __len__(self):
        return len(self.rows)

    def __getitem__(self, idx):
        ex = self.rows[idx]
        input_ids, attn, labels = tokenize_and_mask(self.tokenizer, ex["question"], ex.get("rationale",""), ex.get("answer",""), self.prompt_template)
        return {"input_ids": torch.tensor(input_ids, dtype=torch.long),
                "attention_mask": torch.tensor(attn, dtype=torch.long),
                "labels": torch.tensor(labels, dtype=torch.long)}

def collate_causal(batch, pad_token_id):
    max_len = max(x["input_ids"].size(0) for x in batch)
    input_ids = []
    attention_mask = []
    labels = []
    for ex in batch:
        pad = max_len - ex["input_ids"].size(0)
        input_ids.append(torch.cat([ex["input_ids"], torch.full((pad,), pad_token_id, dtype=torch.long)]))
        attention_mask.append(torch.cat([ex["attention_mask"], torch.zeros((pad,), dtype=torch.long)]))
        labels.append(torch.cat([ex["labels"], torch.full((pad,), -100, dtype=torch.long)]))
    return {"input_ids": torch.stack(input_ids),
            "attention_mask": torch.stack(attention_mask),
            "labels": torch.stack(labels)}

# ---------------------
# evaluation() adapted from your snippet
# ---------------------
def evaluation(model, train_config, eval_dataloader, local_rank, tokenizer, wandb_run):
    """
    Evaluate the model on eval_dataloader.
    Returns (eval_ppl, eval_epoch_loss, val_step_loss_list, val_step_perplexity_list)
    """
    model.eval()
    eval_preds = []
    val_step_loss = []
    val_step_perplexity = []
    eval_loss = 0.0
    total_eval_steps = 0

    device = next(model.parameters()).device
    with MemoryTrace() as memtrace:
        with torch.no_grad():
            for step, batch in enumerate(tqdm(eval_dataloader, colour="green", desc="evaluating Epoch", dynamic_ncols=True)):
                total_eval_steps += 1
                # move to device
                for k in batch.keys():
                    batch[k] = batch[k].to(device)
                outputs = model(**batch)
                loss = outputs.loss
                if train_config.save_metrics:
                    val_step_loss.append(loss.detach().float().item())
                    val_step_perplexity.append(float(torch.exp(loss.detach().float())))
                eval_loss += loss.detach().float()
                # decode greedy argmax of logits (simple evaluation)
                preds = torch.argmax(outputs.logits, dim=-1)
                eval_preds.extend(tokenizer.batch_decode(preds.detach().cpu().numpy(), skip_special_tokens=True))
    eval_epoch_loss = eval_loss / max(1, len(eval_dataloader))
    eval_ppl = float(torch.exp(eval_epoch_loss))
    if wandb_run:
        wandb_run.log({'eval/perplexity': eval_ppl, 'eval/loss': float(eval_epoch_loss)}, commit=False)
    return eval_ppl, float(eval_epoch_loss), val_step_loss, val_step_perplexity

# ---------------------
# train() adapted (keeps your structure but removes undefined helpers)
# ---------------------
def train(model, train_dataloader, eval_dataloader, tokenizer, optimizer, lr_scheduler, gradient_accumulation_steps, train_config, wandb_run=None):
    """
    Train loop adapted from your provided code.
    Expects train_dataloader to yield dicts with tensors.
    """
    local_rank = None
    rank = None
    # autocast = nullcontext  # use fp16 via model dtype; no amp here
    use_fp16 = getattr(train_config, "mixed_precision", False)
    scaler = GradScaler(enabled=use_fp16)
    train_prep = []
    train_loss = []
    val_prep = []
    val_loss = []

    if train_config.save_metrics:
        metrics_filename = f"{train_config.output_dir}/metrics_data_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.json"
        train_step_perplexity = []
        train_step_loss = []
        val_step_loss = []
        val_step_perplexity = []

    epoch_times = []
    checkpoint_times = []
    results = {}
    best_val_loss = float("inf")
    total_train_steps = 0
    max_steps_reached = False

    device = next(model.parameters()).device

    for epoch in range(train_config.num_epochs):
        if max_steps_reached:
            break
        epoch_start_time = time.perf_counter()
        with MemoryTrace() as memtrace:
            model.train()
            total_loss = 0.0
            pbar = tqdm(colour="blue", desc=f"Training Epoch: {epoch+1}", total=math.ceil(len(train_dataloader)/gradient_accumulation_steps), dynamic_ncols=True)
            with profile(train_config, local_rank) as profile_context:
                optimizer.zero_grad()
                for step, batch in enumerate(train_dataloader):
                    total_train_steps += 1
                    # optional max-train-step control
                    if getattr(train_config, "max_train_step", 0) > 0 and total_train_steps > train_config.max_train_step:
                        max_steps_reached = True
                        print("max training steps reached, stopping training")
                        break
                    # move to device
                    for key in batch.keys():
                        batch[key] = batch[key].to(device)
                    # with autocast():
                    #     outputs = model(**batch)
                    #     loss = outputs.loss

                    # loss = loss / gradient_accumulation_steps

                    # if train_config.save_metrics:
                    #     train_step_loss.append(loss.detach().float().item())
                    #     train_step_perplexity.append(float(torch.exp(loss.detach().float())))

                    # total_loss += loss.detach().float()
                    # loss.backward()

                    # with autocast(enabled=use_fp16):
                    #     outputs = model(**batch)
                    #     loss = outputs.loss

                    with torch.amp.autocast(device_type="cuda", enabled=use_fp16):
                        outputs = model(**batch)
                        loss = loss / gradient_accumulation_steps

                    if torch.isnan(loss):
                        print("NaN detected, skipping batch")
                        optimizer.zero_grad()
                        continue

                    if use_fp16:
                        scaler.scale(loss).backward()
                    else:
                        loss.backward()

                    if (step + 1) % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:
                        if train_config.gradient_clipping:
                            if use_fp16:
                                scaler.unscale_(optimizer)
                            torch.nn.utils.clip_grad_norm_(model.parameters(), train_config.gradient_clipping_threshold)
                        if use_fp16:
                            scaler.step(optimizer)
                            scaler.update()
                        else:
                            optimizer.step()
                        optimizer.zero_grad()
                        pbar.update(1)


                    if (step + 1) % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:
                        if train_config.gradient_clipping and train_config.gradient_clipping_threshold > 0.0:
                            torch.nn.utils.clip_grad_norm_(model.parameters(), train_config.gradient_clipping_threshold)
                        optimizer.step()
                        optimizer.zero_grad()
                        pbar.update(1)

                    if train_config.use_profiler or train_config.flop_counter:
                        profile_context.step()

                    if wandb_run:
                        wandb_run.log({
                            'train/epoch': epoch + 1,
                            'train/step': epoch * len(train_dataloader) + step,
                            'train/loss': loss.detach().float(),
                        })

                    pbar.set_description(f"Training Epoch: {epoch+1}/{train_config.num_epochs} step {step}/{len(train_dataloader)} (loss: {loss.detach().float():.4f})")

                    # periodic validation
                    if step % 50 == 0 and train_config.run_validation and eval_dataloader is not None:
                        eval_ppl, eval_epoch_loss, temp_val_loss, temp_step_perplexity = evaluation(model, train_config, eval_dataloader, local_rank, tokenizer, wandb_run)
                        if train_config.save_metrics:
                            val_step_loss.extend(temp_val_loss)
                            val_step_perplexity.extend(temp_step_perplexity)
                        model.train()

                    if train_config.save_metrics:
                        save_to_json(metrics_filename, train_step_loss, train_loss, train_step_perplexity, train_prep, val_step_loss, val_loss, val_step_perplexity, val_prep)
                pbar.close()

        epoch_end_time = time.perf_counter() - epoch_start_time
        epoch_times.append(epoch_end_time)
        train_epoch_loss = total_loss / max(1, len(train_dataloader))
        train_perplexity = float(torch.exp(train_epoch_loss))
        train_prep.append(float(train_perplexity))
        train_loss.append(float(train_epoch_loss))
        memtrace.print_stats()
        try:
            lr_scheduler.step()
        except Exception:
            pass

        # run validation at epoch end
        if train_config.run_validation and eval_dataloader is not None:
            eval_ppl, eval_epoch_loss, temp_val_loss, temp_step_perplexity = evaluation(model, train_config, eval_dataloader, local_rank, tokenizer, wandb_run)
            if train_config.save_metrics:
                val_step_loss.extend(temp_val_loss)
                val_step_perplexity.extend(temp_step_perplexity)

            # save checkpoint
            if train_config.save_model:
                epoch_dir = os.path.join(train_config.output_dir, f"epoch{epoch+1}")
                os.makedirs(epoch_dir, exist_ok=True)
                # Save the model
                model.save_pretrained(epoch_dir)
                print(f"Model saved in {epoch_dir}")

            if eval_epoch_loss < best_val_loss:
                best_val_loss = eval_epoch_loss
                print(f"best eval loss on epoch {epoch+1} is {best_val_loss:.4f}")
            val_loss.append(float(best_val_loss))
            val_prep.append(float(eval_ppl))

        print(f"Epoch {epoch+1}: train_perplexity={train_perplexity:.4f}, train_epoch_loss={train_epoch_loss:.4f}, epoch time {epoch_end_time:.1f}s")

        # save metrics
        if train_config.save_metrics:
            save_to_json(metrics_filename, train_step_loss, train_loss, train_step_perplexity, train_prep, val_step_loss, val_loss, val_step_perplexity, val_prep)

    # aggregate results
    avg_epoch_time = sum(epoch_times) / max(1, len(epoch_times))
    avg_checkpoint_time = sum(checkpoint_times) / max(1, len(checkpoint_times)) if checkpoint_times else 0
    results["avg_train_prep"] = sum(train_prep)/len(train_prep) if train_prep else 0.0
    results["avg_train_loss"] = sum(train_loss)/len(train_loss) if train_loss else 0.0
    if train_config.run_validation:
        results["avg_eval_prep"] = sum(val_prep)/len(val_prep) if val_prep else 0.0
        results["avg_eval_loss"] = sum(val_loss)/len(val_loss) if val_loss else 0.0
    results["avg_epoch_time"] = avg_epoch_time
    results["avg_checkpoint_time"] = avg_checkpoint_time
    if train_config.save_metrics:
        results["metrics_filename"] = metrics_filename
    return results

# ---------------------
# Launcher main
# ---------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model", default="meta-llama/Llama-3.2-3B-Instruct", help="HF model id or local path")
    ap.add_argument("--train_file", default="data/gsm8k_train_sft.jsonl", help="SFT training JSONL")
    ap.add_argument("--subset", type=int, default=500, help="use first N examples (0 = full)")
    ap.add_argument("--out", default="checkpoints/vanilla_sft_direct", help="output dir for checkpoints")
    ap.add_argument("--epochs", type=int, default=1)
    ap.add_argument("--batch", type=int, default=1)
    ap.add_argument("--grad_accum", type=int, default=8)
    ap.add_argument("--lr", type=float, default=2e-5)
    ap.add_argument("--max_seq_len", type=int, default=256)
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--fp16", action="store_true", help="use fp16 model dtype")
    args = ap.parse_args()

    # prepare data
    prepare_gsm8k_sft(args.train_file)

    # load tokenizer + model
    print("[launcher] Loading tokenizer + model:", args.model)
    tokenizer = AutoTokenizer.from_pretrained(args.model, use_auth_token=True)
    if getattr(tokenizer, "pad_token_id", None) is None:
        tokenizer.pad_token = tokenizer.eos_token

    # dtype = torch.float16 if args.fp16 else torch.float32
    # model = AutoModelForCausalLM.from_pretrained(args.model, device_map="auto", torch_dtype=dtype, low_cpu_mem_usage=True)

    dtype = torch.float32
    model = AutoModelForCausalLM.from_pretrained(
        args.model,
        device_map="auto",
        torch_dtype=dtype,
        low_cpu_mem_usage=True
    )
    
    model.gradient_checkpointing_enable()
    print("[launcher] Model loaded. sample param device:", next(model.parameters()).device)

    # build datasets
    subset = args.subset if args.subset > 0 else None
    ds = JsonlCausalDataset(args.train_file, tokenizer, max_examples=subset)
    # small validation split: last 10% of ds
    n = len(ds)
    n_val = max(1, int(0.1 * n)) if n>1 else 0
    if n_val:
        train_rows = ds.rows[:-n_val]
        val_rows = ds.rows[-n_val:]
        # write temporary jsonls for simplicity
        tmp_train = os.path.join(args.out, "tmp_train.jsonl")
        tmp_val = os.path.join(args.out, "tmp_val.jsonl")
        os.makedirs(args.out, exist_ok=True)
        with open(tmp_train, "w", encoding="utf-8") as f:
            for r in train_rows: f.write(json.dumps(r, ensure_ascii=False)+"\n")
        with open(tmp_val, "w", encoding="utf-8") as f:
            for r in val_rows: f.write(json.dumps(r, ensure_ascii=False)+"\n")
        train_dataset = JsonlCausalDataset(tmp_train, tokenizer, max_examples=None)
        val_dataset = JsonlCausalDataset(tmp_val, tokenizer, max_examples=None)
    else:
        train_dataset = ds
        val_dataset = None

    # dataloaders
    collator = lambda batch: collate_causal(batch, pad_token_id=tokenizer.pad_token_id)
    train_loader = DataLoader(train_dataset, batch_size=args.batch, shuffle=True, collate_fn=collator, num_workers=2)
    eval_loader = DataLoader(val_dataset, batch_size=args.batch, shuffle=False, collate_fn=collator, num_workers=2) if val_dataset else None

    print(f"[launcher] train size={len(train_dataset)}, val size={len(val_dataset) if val_dataset else 0}")

    # optimizer & scheduler
    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=0.0)
    scheduler = StepLR(optimizer, step_size=1, gamma=0.85)

    # train_config simple object to pass to train()
    class Cfg:
        pass
    cfg = Cfg()
    cfg.num_epochs = args.epochs
    cfg.gradient_accumulation_steps = args.grad_accum
    cfg.gradient_clipping = True
    cfg.gradient_clipping_threshold = 1.0
    cfg.run_validation = False if eval_loader else False
    cfg.save_model = True
    cfg.save_metrics = True
    cfg.output_dir = args.out
    cfg.max_train_step = 0
    cfg.max_eval_step = 0
    cfg.use_profiler = False
    cfg.flop_counter = False
    cfg.batching_strategy = "padding"
    cfg.context_length = args.max_seq_len
    cfg.num_workers_dataloader = 2
    cfg.per_device_train_batch_size = args.batch
    cfg.lr = args.lr
    cfg.seed = args.seed
    cfg.mixed_precision = args.fp16

    # seed
    torch.manual_seed(cfg.seed)
    random.seed(cfg.seed)

    # call train()
    print("[launcher] Starting training. Output dir:", cfg.output_dir)
    os.makedirs(cfg.output_dir, exist_ok=True)
    results = train(model, train_loader, eval_loader, tokenizer, optimizer, scheduler, cfg.gradient_accumulation_steps, cfg, None)

    print("[launcher] Training finished. Summary results:")
    for k,v in results.items():
        print(f"  {k}: {v}")
    print("Done.")

if __name__ == "__main__":
    main()
